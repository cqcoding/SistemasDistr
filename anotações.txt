1Ô∏è‚É£ Uso de Map para Contar Pesquisas Frequentes
O c√≥digo usa um Map<String, Integer> para armazenar quantas vezes cada pesquisa foi feita. O funcionamento √© simples:

Se a palavra pesquisada j√° est√° no mapa, soma +1.
Se n√£o est√°, adiciona com valor 1.
üìå Exemplo de como funciona no c√≥digo:

pesquisasFrequentes.put(palavra, pesquisasFrequentes.getOrDefault(palavra, 0) + 1);
Isso significa:

getOrDefault(palavra, 0): Se a palavra j√° foi pesquisada antes, pega o valor dela; sen√£o, usa 0.
+1: Soma mais uma ocorr√™ncia.
put(): Salva a nova contagem no mapa.

üìå Se tivermos essas buscas:

pesquisar("java")
pesquisar("java")
pesquisar("rmi")
pesquisar("java")
pesquisar("socket")
O Map vai ficar assim:
{
    "java": 3,
    "rmi": 1,
    "socket": 1
}

2Ô∏è‚É£ Medindo Tempo de Resposta (System.nanoTime())
O c√≥digo mede quanto tempo uma pesquisa demora usando System.nanoTime().

üìå Como funciona:

Antes de come√ßar a pesquisa, salva o tempo inicial:
long inicio = System.nanoTime();
Executa a pesquisa.
Depois de terminar, calcula o tempo total gasto:
long duracao = (System.nanoTime() - inicio) / 100000;  // Converte para d√©cimas de segundo
üìå Exemplo de tempo medido:

Pesquisa "java" demorou 12 d√©cimas de segundo.
Pesquisa "rmi" demorou 8 d√©cimas de segundo.

3Ô∏è‚É£ Ordena√ß√£o das Pesquisas Mais Frequentes
O c√≥digo precisa pegar as 10 pesquisas mais frequentes e mostrar ordenadas. Para isso, ele converte o Map para uma List e usa sort().

üìå No c√≥digo:
List<Map.Entry<String, Integer>> topPesquisas = new ArrayList<>(pesquisasFrequentes.entrySet());
topPesquisas.sort((a, b) -> b.getValue().compareTo(a.getValue()));  // Ordena de maior para menor
üìå Exemplo de sa√≠da esperada:
Top 10 pesquisas mais comuns:
1. java: 15
2. socket: 12
3. rmi: 8
4. distribu√≠do: 5

4Ô∏è‚É£ Constru√ß√£o Eficiente de Strings com StringBuilder
Em vez de usar String (que √© imut√°vel e cria v√°rios objetos na mem√≥ria), o c√≥digo usa StringBuilder.

üìå No c√≥digo:
StringBuilder stats = new StringBuilder();
stats.append("Top 10 pesquisas mais comuns:\n");
Isso evita que o Java fique criando novos objetos toda vez que adicionamos uma linha de texto.

5Ô∏è‚É£ Atualiza√ß√£o das Estat√≠sticas Apenas Quando H√° Mudan√ßas
O c√≥digo n√£o usa um timer para atualizar as estat√≠sticas o tempo todo. Ele s√≥ atualiza quando algo muda, o que economiza processamento.

üìå Como funciona:

Sempre que algu√©m faz uma pesquisa, o c√≥digo atualiza pesquisasFrequentes e temposResposta.
Sempre que um Barrel adiciona URLs, o c√≥digo atualiza barrelsAtivos.
Quando um cliente chama pagina_estatisticas(), ele j√° recebe os dados mais recentes sem precisar esperar.
üìå Resumo do que voc√™ precisa saber
‚úÖ Map armazena as pesquisas mais comuns e o tamanho dos Barrels.
‚úÖ System.nanoTime() mede o tempo de resposta.
‚úÖ sort() organiza as pesquisas mais feitas.
‚úÖ StringBuilder evita desperd√≠cio de mem√≥ria ao montar o relat√≥rio.
‚úÖ O c√≥digo n√£o usa atualiza√ß√£o peri√≥dica, ele s√≥ atualiza quando algo muda.

____________________________________________________________________________________________________________________________

 //PORQUE USAMOS MAP AO INVES DE LIST
    /*1 - Evita Duplica√ß√£o
        Map: cada chave (uma consulta feita) aparece s√≥ 1 vez
        List: precisaria percorrer toda a lista p/ ver se a chave j√° existe antes de incrementar um contador, 
        o que seria ineficiente.
    2 - Melhor Desempenho
        No hashmap √© muito mais r√°pido fazer a inser√ß√£o, busca e atualiza√ß√£o de uma chave do que percorrer uma list
    3 - Mais f√°cil de contar as pesquisas
        Evita percorrer uma lista procurando um item p/ atualizar seu contador
    4 - √â f√°cil de ordenar e filtrar
        **ter masi infos sobre
    5 - Se v√°rias threads estiverem atualizando as estat√≠sticas ao mesmo tempo, um ConcurrentHashMap 
    pode ser eficiente p/ evitar problemas de concorr√™ncia sem precisar de bloqueios pesados
    */

___________________________________________________________________________________________________________________________-

No WEB CROWLER:
--> Criamos uma refer√™ncia ao GatewayServer usando RMI.
‚úÖ Cada URL visitada √© enviada ao GatewayServer para indexa√ß√£o.
‚úÖ Se houver erro ao conectar ao servidor, ele ser√° tratado.
-----------------------------------------------------------------------------------------------------------------------------

Fluxo entre os c√≥digos
WebCrawler:

Conecta-se ao GatewayServer via RMI.
Coleta URLs das p√°ginas visitadas e as envia ao GatewayServer para indexa√ß√£o.
GatewayServer:

Atua como intermedi√°rio entre os componentes.
Indexa URLs e distribui as palavras para os Barrels.
Usa Reliable Multicast para garantir que todas as inst√¢ncias de Barrels tenham os mesmos dados.
Garante que as pesquisas sejam distribu√≠das corretamente.
Downloader:

Obt√©m URLs do Index atrav√©s do m√©todo get_url().
Baixa o conte√∫do da p√°gina e extrai palavras-chave.
Envia palavras extra√≠das para os Barrels armazenarem via save_word(palavra, url).
Barrels:

Armazena e gerencia palavras indexadas e suas URLs associadas.
Responde a pesquisas feitas pelo GatewayServer.

------------------------------------------------------------------------------------------------------------------------------
Downloader busca URLs da fila do Barrel p poder baixar o conte√∫do das paginas

----------------------------------------------------------------------------------------------------------------------------
APRENDIZADO DE MAQUINA P IDENTIFICAR AS STOP WORDS
--> Usamos uma abordagem que treina um classificador bin√°rio para determinar se uma palavra √© uma stop word ou n√£o
--> Usamos a biblioteca Weka p/ construir e treinar nosso modelo
Passos
Prepara√ß√£o dos Dados:
	Precisamos de um conjunto de dados rotulado onde cada palavra √© marcada como stop word ou n√£o stop word
	- Criamos um arquivo ARFF (Attribute-Relation File Format) para armazenar esses dados -- stopWords.arff

Treinamento do Modelo:
	Usamos um classificador como Naive Bayes para treinar o modelo com os dados rotulados

Implementa√ß√£o da Filtragem de Stop Words:
	Integramos o modelo treinado ao WebCrawler p/ identificar e remover as stop words

------------------------------------
O arquivo urlsIndexados.txt √© atualizado no m√©todo salvarURLs() dentro da classe BarrelServer (implementada em Barrels.java). Este m√©todo √© chamado sempre que uma nova URL √© indexada no m√©todo indexar_URL() ou quando os dados s√£o sincronizados entre os barrels no m√©todo sincronizarDados(). Essencialmente, cada vez que o √≠ndice de URLs √© alterado, o arquivo √© reescrito para persistir as mudan√ßas.